{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Details\n",
    "\n",
    "The project is part of Udacity Deep Reinforcement Learning Nano Degree program, involving training of 20 double-jointed arms to move to target locations. The arms are represented by actor-critic neural networks trained using a [DDPG](https://arxiv.org/abs/1509.02971) framework. The problem is episodic and invloves environment states percieved by the DDPG agents, **continuous actions** selected and performed by the agents, rewards returned from the environment for each action at the next time step, and transition to next states. <br>\n",
    "\n",
    "**Observation space** has 33 dimensions corresponding to position, rotation, velocity, and angular velocities of the arms. <br>\n",
    "**Action space** has 4 dimensions corresponding to torque applicable to two joints. <br>\n",
    "**Reward** is +0.1 for each time step that the agents' hands are at target locations, so the goal of the agents is to maintain their positions at target locations for as many time steps as possible. The problem is considered solved if the agents attains an average score of 30 over 100 consecutive episodes.<br>\n",
    "\n",
    "# Getting Started\n",
    "\n",
    "## Conda Environment\n",
    "For those using conda, you can create a new conda environment as follows.\n",
    "\n",
    "+ Windows\n",
    "```\n",
    "conda create --name your_env_name python=3.6 \n",
    "activate your_env_name \n",
    "```\n",
    "+ Linux or MAC\n",
    "```\n",
    "conda create --name your_env_name python=3.6 \n",
    "source activate your_env_name \n",
    "```\n",
    "\n",
    "## Project Dependencies\n",
    "\n",
    "The project requires the following libraries to be correctly installed.\n",
    "\n",
    "1. Unity ML-Agents \n",
    "The installation instruction can be found at Unity-ML website\n",
    "    - Download Unity\n",
    "    - Clone the ML-Agents Toolkit GitHub repository\n",
    "    ```\n",
    "        git clone https://github.com/Unity-Technologies/ml-agents.git\n",
    "    ```\n",
    "    - Download requirements.txt and install\n",
    "    ```\n",
    "        conda install --yes --file requirements.txt\n",
    "    ```\n",
    "2. Pytorch \n",
    "The pytorch version to install depends on your system configuration (e.g., operating systems, package managers, python versions, and availibility of CUDA).\n",
    "    - Select the configuration of your system at pytorch website and follow the installation instruction described on the webpage.\n",
    "    \n",
    "# Instructions\n",
    "\n",
    "A DDPG agent is based on an actor network and a critic network, both defined in `model.py`. The agent itself is described in `ddpg_agent.py`. Section 4 of `Continuous_Control.ipynb` describes an approach to train DDPG agents. A snippet of the code to train an agent is shown below.\n",
    "\n",
    "```\n",
    "# determine torch computing device\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# set up environment\n",
    "env = UnityEnvironment(file_name='/data/Reacher_Linux_NoVis/Reacher.x86_64') # path to a Unity Reacher environment\n",
    "action_size = env.brains[env.brain_names[0]].vector_action_space_size  # get dimension of action space\n",
    "state_size = env.reset(train_mode=False)[env.brain_names[0]].vector_observations.size # get dimension of state space\n",
    "\n",
    "# agent configuration\n",
    "settings = {'buffer_size':int(1e6), 'batch_size':256, 'gamma':0.99, 'tau':1e-3, 'lr_actor':1e-3, 'lr_critic':1e-3,\n",
    "           'weight_decay':0., 'epsilon':1., 'epsilon_decay':1e-6, 'num_batch_permute':10}\n",
    "           \n",
    "# initilize an DDPG agent \n",
    "agent = Agent(device, state_size, action_size, random_seed, **settings)\n",
    "\n",
    "# train the agent  \n",
    "scores = ddpg()\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
